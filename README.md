# üìâ AI Token Optimizer Toolkit

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/)

Une suite d'outils en ligne de commande (CLI) con√ßue pour le **Prompt Engineering** et l'optimisation des co√ªts li√©s aux LLMs (GPT-4, Claude, Mistral, etc.).

Ce d√©p√¥t contient deux scripts distincts pour transformer vos fichiers de donn√©es (`.json`) et r√©duire drastiquement la consommation de tokens :

1.  **`token_optimizer.py`** : Convertit en **YAML Flow** ou **JSON Minifi√©** (Garde la structure, haute compatibilit√©).
2.  **`json_flattener.py`** : Convertit en **Texte Compact** (Supprime la syntaxe, √©conomie maximale).

## üí° Pourquoi ces outils ?

Les mod√®les de langage (LLM) facturent au token. La structure JSON standard est verbeuse (guillemets, accolades, sauts de ligne). Ces scripts nettoient vos donn√©es pour ne garder que l'essentiel.

### Comparatif des Gains

Pour l'entr√©e : `{"utilisateur": {"nom": "Alice", "id": 101}, "roles": ["admin"]}`

| Format | Script | Contenu R√©sultant | Tokens (est.) |
| :--- | :--- | :--- | :--- |
| **JSON Standard** | *(Original)* | `{"utilisateur": { "nom": ...` | **~22** |
| **JSON Minifi√©** | `token_optimizer.py` | `{"utilisateur":{"nom":"Alice"...` | **~18** |
| **YAML Flow** | `token_optimizer.py` | `{utilisateur: {nom: Alice...` | **~14** |
| **Flat Text** üöÄ | `json_flattener.py` | `utilisateur:nom:Alice, id:101...` | **~10** |

> **R√©sultat :** Vous pouvez √©conomiser **30% √† 50%** de tokens sur des gros fichiers de contexte.

---

## üõ†Ô∏è Installation

1. Clonez ce d√©p√¥t :
   ```bash
   git clone [https://github.com/votre-nom/ai-token-optimizer.git](https://github.com/votre-nom/ai-token-optimizer.git)
   cd ai-token-optimizer
